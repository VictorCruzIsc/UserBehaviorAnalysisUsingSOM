source('coolBlueHotRed.R')
working_directory <- "./Documents/git/UserBehaviorAnalysisUsingSOM/R"
output_file_folder <- "./r_trained_som"
dataset_file_folder <- "./chunks"
train_dataset_max_size <- 100000
epochs <- 25
learning_rate <- c(0.05, 0.01)
neighbourhood <- "circular"
topography <- "rectangular"
require(kohonen)
setup_environment <- function(working_directory){
getwd()
setwd(working_directory)
getwd()
}
get_datasets <- function(build_file, train_file, evaluate_file, max_elements){
# Build dataset
import_build_dataset <- read.table(build_file)
length(import_build_dataset[,1])
# Train dataset
import_train_dataset <- read.table(train_file)
total_import_train_dataset <- length(import_train_dataset[,1])
# If training dataset length is bigger than training_elements_subset, a subset is obtained.
if(total_import_train_dataset > max_elements){
train_samples <- sample(total_import_train_dataset, max_elements, replace = FALSE)
import_train_dataset<-import_train_dataset[train_samples,]
}
import_evaluate_dataset <- read.table(evaluate_file)
datasets <- list(build = import_build_dataset,
train = import_train_dataset,
evaluate = import_evaluate_dataset)
return (datasets)
}
get_som_solution <- function(x_neurons, y_neurons, topography,
train_elements, num_epochs, learning_rate,
build_elements, keep_data){
input_vectors_matrix <- as.matrix(scale(train_elements))
build_vectors_matrix <- as.matrix(scale(build_elements))
som_grid <- somgrid(xdim = x_neurons, ydim = y_neurons, topo=topography)
som_model <- som(input_vectors_matrix, som_grid,
rlen = num_epochs, alpha = learning_rate,
build_vectors_matrix, keep.data = keep_data)
return (som_model)
}
get_som_exportable_values <- function(raw_data, user){
raw_data <- cbind(raw_data, user)
raw_data <- cbind(raw_data, 0)
raw_data <- cbind(raw_data, 0)
raw_data <- cbind(raw_data, 0)
return(raw_data)
}
get_trained_som <- function(users, lattice_dimensions,
output_file_folder, dataset_file_folder,
train_dataset_max_size, epochs,
learning_rate, neighbourhood,
topography){
for(user in users){
for(dimension in lattice_dimensions){
#print(paste(user, dimension))
trained_som_name <- c("trained_lattice_", user, "_", dimension, "_", epochs, ".txt")
build_dataset_input_name <- c("1", ".", user, ".txt")
train_dataset_input_name <- c("2", ".", user, ".txt")
evaluate_dataset_input_name <- c("3", ".", user, ".txt")
trained_som_destination_path <- paste(c(output_file_folder,"/",trained_som_name), collapse = "")
build_dataset_path <- paste(c(dataset_file_folder, "/", build_dataset_input_name), collapse = "")
train_dataset_path <- paste(c(dataset_file_folder, "/", train_dataset_input_name), collapse = "")
evaluate_dataset_path <- paste(c(dataset_file_folder, "/", evaluate_dataset_input_name), collapse = "")
# Obtaining datasets
datasets <- get_datasets(build_dataset_path, train_dataset_path, evaluate_dataset_path, train_dataset_max_size)
# SOM algoruthm
som_model <- get_som_solution(dimension, dimension, topography,
datasets$train, epochs, learning_rate,
datasets$build, TRUE)
# Extract SOM trained values
som_trained_neurons <- get_som_exportable_values(som_model$codes[[1]], user)
# Export elements for C++ analysis
write.table(som_trained_neurons, file=trained_som_destination_path, sep=" ",
col.names = FALSE, row.names = FALSE)
}
}
}
working_directory <- "./Documents/git/UserBehaviorAnalysisUsingSOM/R"
output_file_folder <- "./r_trained_som"
dataset_file_folder <- "./chunks"
train_dataset_max_size <- 100000
epochs <- 25
learning_rate <- c(0.05, 0.01)
neighbourhood <- "circular"
topography <- "rectangular"
require(kohonen)
setup_environment(working_directory)
users <- c(4, 5, 9, 10)
lattice_dimensions <- c(50, 75, 100, 125)
get_trained_som(users, lattice_dimensions,
output_file_folder, dataset_file_folder,
train_dataset_max_size, epochs,
learning_rate, neighbourhood,topography)
getwd()
trained_som_destination_path <- paste(c(output_file_folder,"/",trained_som_name), collapse = "")
trained_som_name <- c("trained_lattice_", user, "_", dimension, "_", epochs, ".txt")
working_directory <- "./Documents/git/UserBehaviorAnalysisUsingSOM/R"
setup_environment <- function(working_directory){
getwd()
setwd(working_directory)
getwd()
}
setup_environment(working_directory)
trained_som_destination_path <- paste(c(output_file_folder,"/",trained_som_name), collapse = "")
trained_som_name <- c("trained_lattice_", user, "_", dimension, "_", epochs, ".txt")
trained_som_name <- c("trained_lattice_", 4, "_", dimension, "_", epochs, ".txt")
working_directory <- "./Documents/git/UserBehaviorAnalysisUsingSOM/R"
output_file_folder <- "./r_trained_som"
dataset_file_folder <- "./chunks"
train_dataset_max_size <- 100000
epochs <- 25
learning_rate <- c(0.05, 0.01)
neighbourhood <- "circular"
topography <- "rectangular"
trained_som_name <- c("trained_lattice_", 4, "_", 50, "_", epochs, ".txt")
trained_som_destination_path <- paste(c(output_file_folder,"/",trained_som_name), collapse = "")
trained_som_destination_path
setup_environment(working_directory)
trained_som_name <- c("trained_lattice_", 4, "_", dimension, "_", epochs, ".txt")
trained_som_name <- c("trained_lattice_", 4, "_", 50, "_", epochs, ".txt")
build_dataset_input_name <- c("1", ".", 4, ".txt")
train_dataset_input_name <- c("2", ".", 4, ".txt")
evaluate_dataset_input_name <- c("3", ".", 4, ".txt")
trained_som_destination_path <- paste(c(output_file_folder,"/",trained_som_name), collapse = "")
build_dataset_path <- paste(c(dataset_file_folder, "/", build_dataset_input_name), collapse = "")
train_dataset_path <- paste(c(dataset_file_folder, "/", train_dataset_input_name), collapse = "")
evaluate_dataset_path <- paste(c(dataset_file_folder, "/", evaluate_dataset_input_name), collapse = "")
datasets <- get_datasets(build_dataset_path, train_dataset_path, evaluate_dataset_path, train_dataset_max_size)
setup_environment(working_directory)
datasets <- get_datasets(build_dataset_path, train_dataset_path, evaluate_dataset_path, train_dataset_max_size)
datasets <- get_datasets(build_dataset_path, train_dataset_path, evaluate_dataset_path, train_dataset_max_size)
trained_som_destination_path <- paste(c(output_file_folder,"/",trained_som_name), collapse = "")
trained_som_destination_path
trained_som_destination_path
trained_som_name <- c("trained_lattice_", 4, "_", 50, "_", epochs, ".txt")
trained_som_destination_path <- paste(c(output_file_folder,"/",trained_som_name), collapse = "")
require(kohonen)
setup_environment(working_directory)
users <- c(4, 5, 9, 10)
lattice_dimensions <- c(50, 75, 100, 125)
setup_environment <- function(working_directory){
getwd()
setwd(working_directory)
getwd()
}
get_datasets <- function(build_file, train_file, evaluate_file, max_elements){
# Build dataset
import_build_dataset <- read.table(build_file)
length(import_build_dataset[,1])
# Train dataset
import_train_dataset <- read.table(train_file)
total_import_train_dataset <- length(import_train_dataset[,1])
# If training dataset length is bigger than training_elements_subset, a subset is obtained.
if(total_import_train_dataset > max_elements){
train_samples <- sample(total_import_train_dataset, max_elements, replace = FALSE)
import_train_dataset<-import_train_dataset[train_samples,]
}
import_evaluate_dataset <- read.table(evaluate_file)
datasets <- list(build = import_build_dataset,
train = import_train_dataset,
evaluate = import_evaluate_dataset)
return (datasets)
}
build_dataset_input_name <- c("1", ".", 4, ".txt")
train_dataset_input_name <- c("2", ".", 4, ".txt")
evaluate_dataset_input_name <- c("3", ".", 4, ".txt")
trained_som_destination_path <- paste(c(output_file_folder,"/",trained_som_name), collapse = "")
build_dataset_path <- paste(c(dataset_file_folder, "/", build_dataset_input_name), collapse = "")
train_dataset_path <- paste(c(dataset_file_folder, "/", train_dataset_input_name), collapse = "")
evaluate_dataset_path <- paste(c(dataset_file_folder, "/", evaluate_dataset_input_name), collapse = "")
build_dataset_path
train_dataset_path
evaluate_dataset_path
train_dataset_max_size
datasets <- get_datasets(build_dataset_path, train_dataset_path, evaluate_dataset_path, train_dataset_max_size)
working_directory <- "./Documents/git/UserBehaviorAnalysisUsingSOM/R"
setup_environment(working_directory)
getwd()
datasets <- get_datasets(build_dataset_path, train_dataset_path, evaluate_dataset_path, train_dataset_max_size)
